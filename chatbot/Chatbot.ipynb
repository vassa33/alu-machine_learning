{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNBq+5syrdWt5y0uX3ZgkoQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vassa33/alu-machine_learning/blob/main/chatbot/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "Bgu_CkFRdpN-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uV7ozY2TdZE-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre-Process Data**"
      ],
      "metadata": {
        "id": "L1G-y3Tvd53o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "with open('dataset.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Clean the text data\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "questions = [clean_text(pair['question']) for pair in data]\n",
        "answers = [clean_text(pair['answer']) for pair in data]"
      ],
      "metadata": {
        "id": "Wi7qgwmndwv3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenize Text**"
      ],
      "metadata": {
        "id": "vRumneGwd_v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking')\n",
        "\n",
        "def tokenize(texts, is_answer=False):\n",
        "    return tokenizer.batch_encode_plus(\n",
        "        texts,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,  # Adjusted for typical BERT input lengths\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors='tf',\n",
        "        # If tokenizing answers, only return the input IDs without any additional tokens\n",
        "        return_token_type_ids= not is_answer,\n",
        "        return_attention_mask= not is_answer\n",
        "    )\n",
        "\n",
        "tokenized_questions = tokenize(questions)\n",
        "tokenized_answers = tokenize(answers, is_answer=True)"
      ],
      "metadata": {
        "id": "RDOnix3qeRCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prepare Input Tensors for BERT**"
      ],
      "metadata": {
        "id": "8sQjC1_seZxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract input IDs from tokenized answers to use as labels\n",
        "answer_labels = tokenized_answers['input_ids']\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'input_ids': tokenized_questions['input_ids'],\n",
        "        'attention_mask': tokenized_questions['attention_mask']\n",
        "    },\n",
        "    answer_labels\n",
        ")).shuffle(len(questions)).batch(8)"
      ],
      "metadata": {
        "id": "HqMMdtWGeiCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-tune the Model**"
      ],
      "metadata": {
        "id": "evlqw4gdeoii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertForSequenceClassification, BertConfig\n",
        "\n",
        "# Use the number of possible answers as num_labels\n",
        "config = BertConfig.from_pretrained('bert-large-uncased', num_labels=len(set(answers)))\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-large-uncased', config=config)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "model.fit(train_dataset, epochs=3)"
      ],
      "metadata": {
        "id": "A152q9oZeq25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build an Interface for the Model**"
      ],
      "metadata": {
        "id": "eQvOs2qfetkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(question):\n",
        "    cleaned_question = clean_text(question)\n",
        "    inputs = tokenizer.encode_plus(cleaned_question, return_tensors='tf')\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    answer_start = tf.argmax(outputs.start_logits, axis=1).numpy()[0]\n",
        "    answer_end = tf.argmax(outputs.end_logits, axis=1).numpy()[0]\n",
        "    answer_tokens = input_ids[0, answer_start:answer_end+1]\n",
        "    answer = tokenizer.decode(answer_tokens)\n",
        "    return answer\n",
        "\n",
        "def chatbot_interface():\n",
        "    print(\"Welcome to the Agriculture Chatbot. Ask a question related to farming and technology!\")\n",
        "    while True:\n",
        "        question = input(\"Q: \")\n",
        "        if question.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "            print(\"A: Goodbye!\")\n",
        "            break\n",
        "        answer = get_answer(question)\n",
        "        print(f\"A: {answer}\")\n",
        "\n",
        "# Run the chatbot interface\n",
        "chatbot_interface()\n"
      ],
      "metadata": {
        "id": "wKaPoa9TezKF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}